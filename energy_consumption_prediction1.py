# -*- coding: utf-8 -*-
"""energy consumption prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oi0j5U5CjqKculmZyENagaJhFQYgWuq_
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import joblib

# Load the dataset
data = pd.read_csv("/content/smart_home_energy_consumption_large.csv")

data.rename(columns={
    'Home ID': 'home_id',
    'Appliance Type': 'appliance_type',
    'Energy Consumption (kWh)': 'energy_consumption',
    'Time': 'time',
    'Date': 'date',
    'outdoor temperature': 'outdoor_temperature',
    'Season': 'season',
    'Household Size': 'household_size'
}, inplace=True)

data.head()

# Data preprocessing
# Combine date and time into a single datetime column if not already
if 'datetime' not in data.columns:
    data['datetime'] = pd.to_datetime(data['date'] + ' ' + data['time'], format='%d-%m-%Y %H:%M')
    data.drop(['date', 'time'], axis=1, inplace=True)

# Extract time-based features
data['hour'] = data['datetime'].dt.hour
data['day'] = data['datetime'].dt.day
data['month'] = data['datetime'].dt.month

# Drop datetime as it's no longer needed
data.drop(['datetime'], axis=1, inplace=True)

# Separate features and target variable
X = data.drop(columns=['energy_consumption'])
y = data['energy_consumption']

# Identify categorical and numerical columns
categorical_cols = ['home_id', 'appliance_type', 'season']
numerical_cols = ['household_size', 'outdoor_temperature', 'hour', 'day', 'month']

# Preprocessing for numerical and categorical data
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ]
)

# Define the model
model = RandomForestRegressor(n_estimators=100, random_state=42)

# Create and combine preprocessing and modeling pipeline
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', model)
])

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
pipeline.fit(X_train, y_train)

# Make predictions
y_pred = pipeline.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# Save the trained model
joblib.dump(pipeline, 'energy_consumption_model.pkl')

import pickle

filename="trained_model.sav"
pickle.dump(pipeline,open(filename,'wb'))

#loading the saved model
loaded_model=pickle.load(open('trained_model.sav','rb'))

# Prediction for new input data
input_data = (94, 'Fridge', '21:12:00', '06-08-2023', 31.1, 'Winter', 3)

# Preprocess the input data
datetime_input = pd.to_datetime(input_data[3] + ' ' + input_data[2])
hour = datetime_input.hour
day = datetime_input.day
month = datetime_input.month

processed_input = pd.DataFrame({
    'home_id': [input_data[0]],
    'appliance_type': [input_data[1]],
    'household_size': [input_data[6]],
    'outdoor_temperature': [input_data[4]],
    'season': [input_data[5]],
    'hour': [hour],
    'day': [day],
    'month': [month]
})

# Load the trained model
#loaded_model = joblib.load('energy_consumption_model.pkl')

# Predict energy consumption
predicted_consumption = loaded_model.predict(processed_input)

print(f"Predicted Energy Consumption: {predicted_consumption[0]} kW")

